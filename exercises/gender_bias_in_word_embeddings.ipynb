{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "glove_model = api.load(\"glove-wiki-gigaword-100\")  # This loads a 100-dimensional GloVe model trained on Wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cosine_similarity(model, word1, word2):\n",
    "    return np.dot(model[word1], model[word2]) / (np.linalg.norm(model[word1]) * np.linalg.norm(model[word2]))\n",
    "\n",
    "# Example biases\n",
    "professions = [\"legendary\", \"developer\", \"nurse\", \"teacher\",\"queen\",\"king\"]\n",
    "gender_words = [\"man\", \"woman\"]\n",
    "\n",
    "for profession in professions:\n",
    "    for gender in gender_words:\n",
    "        similarity = find_cosine_similarity(glove_model, profession, gender)\n",
    "        print(f\"Cosine similarity between {profession} and {gender}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_embeddings(words, model):\n",
    "    vectors = np.array([model[w] for w in words])\n",
    "    pca = PCA(n_components=2)\n",
    "    vectors_transformed = pca.fit_transform(vectors)\n",
    "    plt.scatter(vectors_transformed[:, 0], vectors_transformed[:, 1])\n",
    "    for i, word in enumerate(words):\n",
    "        plt.annotate(word, xy=(vectors_transformed[i, 0], vectors_transformed[i, 1]))\n",
    "    plt.show()\n",
    "\n",
    "plot_embeddings(professions + gender_words, glove_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debias_gender_specific_words(model, gender_direction, neutral_words):\n",
    "    for word in neutral_words:\n",
    "        word_vec = model[word]\n",
    "        word_bias = np.dot(word_vec, gender_direction) * gender_direction\n",
    "        model[word] = word_vec - word_bias\n",
    "\n",
    "def compute_gender_direction(model, gender_pairs):\n",
    "    gender_direction = np.zeros(model.vector_size)\n",
    "    for a, b in gender_pairs:\n",
    "        gender_direction += model[b] - model[a]\n",
    "    gender_direction /= len(gender_pairs)\n",
    "    return gender_direction\n",
    "\n",
    "# Define gender pairs and neutral words\n",
    "gender_pairs = [(\"man\", \"woman\"), (\"king\", \"queen\"), (\"father\", \"mother\")]\n",
    "neutral_words = professions\n",
    "\n",
    "# Compute the gender direction\n",
    "gender_dir = compute_gender_direction(glove_model, gender_pairs)\n",
    "\n",
    "# Debias\n",
    "debias_gender_specific_words(glove_model, gender_dir, neutral_words)\n",
    "\n",
    "# Check changes\n",
    "for profession in professions:\n",
    "    for gender in gender_words:\n",
    "        similarity = find_cosine_similarity(glove_model, profession, gender)\n",
    "        print(f\"Debiased cosine similarity between {profession} and {gender}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def plot_embeddings(words, model):\n",
    "    vectors = np.array([model[w] for w in words])\n",
    "    pca = PCA(n_components=2)\n",
    "    vectors_transformed = pca.fit_transform(vectors)\n",
    "    plt.scatter(vectors_transformed[:, 0], vectors_transformed[:, 1])\n",
    "    for i, word in enumerate(words):\n",
    "        plt.annotate(word, xy=(vectors_transformed[i, 0], vectors_transformed[i, 1]))\n",
    "    plt.show()\n",
    "\n",
    "plot_embeddings(professions + gender_words, glove_model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
